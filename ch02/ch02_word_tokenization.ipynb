{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tokenization\n",
    "\n",
    "Tokenization: split a document, any string, into discrete **tokens of meaning**.\n",
    "\n",
    "本章主要介绍以下内容：\n",
    "\n",
    "- 把一句话切成token / n-grams\n",
    "- 处理特殊的标点，例如emoticons\n",
    "- stemming / Lemmatization：进一步合并（压缩）所有token\n",
    "- 对每句话创建一个vector representation\n",
    "- sentiment analyzer from handcrafted token scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Challenges\n",
    "\n",
    "### 通常的预处理流程：\n",
    "\n",
    "1. tokenization\n",
    "    - separate punctuation from words\n",
    "    - split contractions: we'll -> we will\n",
    "    - emoticons\n",
    "    - math symbols\n",
    "    - **what is a token?**\n",
    "        - ice cream: 1 token or 2 tokens? \n",
    "    \n",
    "2. stemming\n",
    "    - 根据token 的syllables, prefix, suffix\n",
    "    - processing, processed, process\n",
    "    - 困难：\n",
    "        - remove ing\n",
    "            - ending -> end\n",
    "            - running -> run (not runn)\n",
    "            - sing -> s (wrong)\n",
    "        - plural form:\n",
    "            - words -> word\n",
    "            - bus -> bu (wrong)\n",
    "        - more info: ch05_word2vec\n",
    "\n",
    "3. invisible words\n",
    "    - don't (do that)!\n",
    "    \n",
    "4. n-grams\n",
    "    - including pairs of words\n",
    "    - filter out n-grams that rarely occur together (low frequency)\n",
    "    - 留下一些常用的组合，例如 ice cream, Mr. Smith\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building your vocabulary with a tokenizer\n",
    "\n",
    "#### natural language processing v.s. programming language compiler\n",
    "\n",
    "A tokenizer used for compiling computer languages is often called a **scanner** , **lexical analyzer** or **lexer**.\n",
    "The vocabulary (the set of all the valid tokens) for a computer language is often called a **lexicon**\n",
    "\n",
    "| Natural Language Processing   | Parser   | Tokenizer                        | Vocabulary |\n",
    "|-------------------------------|----------|----------------------------------|------------|\n",
    "| Programming Language Compiler | Compiler | Scanner, Lexer, Lexical Analyzer | Lexicon    |\n",
    "\n",
    "A tokenizer breaks unstructured data, natural language text, into chunks of information that can be counted as discrete elements. (unstructured string -> numerical data structure)\n",
    "\n",
    "#### 最简单的tokenizer: 使用空格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Thomas Jefferson began building Monticello at the age of 26.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thomas', 'Jefferson', 'began', 'building', 'Monticello', 'at', 'the', 'age', 'of', '26.']\n"
     ]
    }
   ],
   "source": [
    "print(sentence.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thomas', 'Jefferson', 'began', 'building', 'Monticello', 'at', 'the', 'age', 'of', '26.']\n"
     ]
    }
   ],
   "source": [
    "print(str.split(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面的例子可以看出，最后一个26后面的句号没有被切分开。通常，word 和punctuation 要分开。后面我们会逐步优化tokenizer。下面，我们先focus on pipeline.\n",
    "\n",
    "### one-hot vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "token_sequence = str.split(sentence)\n",
    "vocab = sorted(set(token_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['26.', 'Jefferson', 'Monticello', 'Thomas', 'age', 'at', 'began', 'building', 'of', 'the']\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the corpus has 10 tokens.\n",
      "the corpus has 10 unique tokens (vocab size).\n",
      "The 0th word: Thomas\tone-hot: [0 0 0 1 0 0 0 0 0 0]\n",
      "The 1th word: Jefferson\tone-hot: [0 1 0 0 0 0 0 0 0 0]\n",
      "The 2th word: began\tone-hot: [0 0 0 0 0 0 1 0 0 0]\n",
      "The 3th word: building\tone-hot: [0 0 0 0 0 0 0 1 0 0]\n",
      "The 4th word: Monticello\tone-hot: [0 0 1 0 0 0 0 0 0 0]\n",
      "The 5th word: at\tone-hot: [0 0 0 0 0 1 0 0 0 0]\n",
      "The 6th word: the\tone-hot: [0 0 0 0 0 0 0 0 0 1]\n",
      "The 7th word: age\tone-hot: [0 0 0 0 1 0 0 0 0 0]\n",
      "The 8th word: of\tone-hot: [0 0 0 0 0 0 0 0 1 0]\n",
      "The 9th word: 26.\tone-hot: [1 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(token_sequence)\n",
    "print('the corpus has {} tokens.'.format(num_tokens))\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "print('the corpus has {} unique tokens (vocab size).'.format(vocab_size))\n",
    "\n",
    "onehot_vectors = np.zeros((num_tokens, vocab_size), int)  # #rows = #token, #cols = |vocab|\n",
    "for i, word in enumerate(token_sequence):\n",
    "    onehot_vectors[i, vocab.index(word)] = 1\n",
    "    print('The {}th word: {}\\tone-hot: {}'.format(i, word, onehot_vectors[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了更好的可视化，我们使用**Pandas**库. \n",
    "使用pandas，每一行代表一个token 的one-hot vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>26.</th>\n",
       "      <th>Jefferson</th>\n",
       "      <th>Monticello</th>\n",
       "      <th>Thomas</th>\n",
       "      <th>age</th>\n",
       "      <th>at</th>\n",
       "      <th>began</th>\n",
       "      <th>building</th>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   26.  Jefferson  Monticello  Thomas  age  at  began  building  of  the\n",
       "0    0          0           0       1    0   0      0         0   0    0\n",
       "1    0          1           0       0    0   0      0         0   0    0\n",
       "2    0          0           0       0    0   0      1         0   0    0\n",
       "3    0          0           0       0    0   0      0         1   0    0\n",
       "4    0          0           1       0    0   0      0         0   0    0\n",
       "5    0          0           0       0    0   1      0         0   0    0\n",
       "6    0          0           0       0    0   0      0         0   0    1\n",
       "7    0          0           0       0    1   0      0         0   0    0\n",
       "8    0          0           0       0    0   0      0         0   1    0\n",
       "9    1          0           0       0    0   0      0         0   0    0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(onehot_vectors, columns=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot 可以想象成在弹钢琴，每一个键代表一个token，依次排开。每次只能弹一个键。例如，第一次弹了第4个键(Thomas), 第二次弹第2个键(Jefferson), 以此类推。\n",
    "\n",
    "\n",
    "通过one-hot vector，我们把一个token 转换成了numbers，以便计算机理解和计算。\n",
    "这种One-hot vector 通常用于：\n",
    "\n",
    "- used in neural nets\n",
    "- sequence-to-sequence language models\n",
    "- generative language models\n",
    "- etc.\n",
    "\n",
    "#### **Point++**: 没有information lost \n",
    "除了空格无法恢复，但是空格本身带的信息很少).\n",
    "\n",
    "#### **Point--**: one-hot vector representation 得到一个十分稀疏的矩阵。\n",
    "\n",
    "对于实际应用场景，impractical. 下面我们预估以下：\n",
    "- 假设我们有3000 books, 每本书有3500行，每行15个单词，所以我们表格的总行数为：\n",
    "\n",
    "`#rows = 3000*3500*15 = 157500000`\n",
    "\n",
    "假设我们vocab 有 100,000 个单词，那我们表格的总列数为：\n",
    "\n",
    "`#cols = 100000`\n",
    "\n",
    "假设matrix 的每个cell 用1个byte 来存储，则matrix 的总大小为：\n",
    "\n",
    "`#size_in_byte = 157500000 * 100000 = 15750000000000`\n",
    "\n",
    "所以总大小是 15.75 TB\n",
    "\n",
    "`size_in_byte / le12 = 15.75`\n",
    "\n",
    "所以我们要对这样one-hot matrix 做**dimension reduction**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-Word\n",
    "\n",
    "许多时候我们发现，词的顺序其实并不太影响我们理解一句话的意思。\n",
    "\n",
    "所以我们又一个假设：the meaning of a sentence can be gleaned from just the words themselves. \n",
    "\n",
    "所以我们可以把所有的单词放在一个bag中，忽略单词之间的顺序。每一个bag 代表一个document，例如，一句话。\n",
    "\n",
    "bag of word vector 可以通过把一个document 中每个token 的one-hot vector 相加得到（OR operation）。所以bag of word vector count the **frequency** of words, **not order**. 以前是每个token 一个长度为|vocab| 的向量，现在是每个document 一个长度为|vocab| 的向量。\n",
    "\n",
    "one-hot vector 好比solo，一次只弹一个键；bag of word 更像和旋，一次可以同时弹多个键。\n",
    "\n",
    "所以通过使用bag of word，我们压缩了初步的one-hot matrix.\n",
    "\n",
    "除此以外，可以使用bag of word 来index document，因为使用bag of word vector 我们可以快速知道某一个document 中是否包含某一个单词。\n",
    "\n",
    "#### set of word\n",
    "\n",
    "下面的代码实现了set of word (区别在于，每个token 只有0:没有出现和1:出现两种状态，而不计数)\n",
    "\n",
    "对于set of word，每个vector 是一个binary vector (0 and 1). Binary vector 的优势是，All modern CPUs have hard\n",
    "wired memory addressing instructions that can efficiently hash, index, and search a large set of binary vectors like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('26.', 1), ('Jefferson', 1), ('Monticello', 1), ('Thomas', 1), ('age', 1), ('at', 1), ('began', 1), ('building', 1), ('of', 1), ('the', 1)]\n"
     ]
    }
   ],
   "source": [
    "sentence_bow = {}\n",
    "for token in sentence.split():\n",
    "    sentence_bow[token] = 1\n",
    "\n",
    "print(sorted(sentence_bow.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为每个token 的计数只可能是0或者1，所以我们可以直接使用一个set 来存储所有出现过的token，这样更省空间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(pd.Series(dict([(token, 1) for token in sentence.split()])), columns=['sent']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thomas</th>\n",
       "      <th>Jefferson</th>\n",
       "      <th>began</th>\n",
       "      <th>building</th>\n",
       "      <th>Monticello</th>\n",
       "      <th>at</th>\n",
       "      <th>the</th>\n",
       "      <th>age</th>\n",
       "      <th>of</th>\n",
       "      <th>26.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sent</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Thomas  Jefferson  began  building  Monticello  at  the  age  of  26.\n",
       "sent       1          1      1         1           1   1    1    1   1    1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面，我们在corpus 中加一些句子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thomas Jefferson began building Monticello at the age of 26.\n",
      "Construction was done mostly by local masons and carpenters.\n",
      "He moved into the South Pavilion in 1770.\n",
      "Turning Monticello into a neoclassical masterpiece was Jefferson's obsession.\n"
     ]
    }
   ],
   "source": [
    "sentences = \"Thomas Jefferson began building Monticello at the age of 26.\\n\"\n",
    "sentences += \"Construction was done mostly by local masons and carpenters.\\n\"\n",
    "sentences += \"He moved into the South Pavilion in 1770.\\n\"\n",
    "sentences += \"Turning Monticello into a neoclassical masterpiece was Jefferson's obsession.\"\n",
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sent0': {'26.': 1,\n",
      "           'Jefferson': 1,\n",
      "           'Monticello': 1,\n",
      "           'Thomas': 1,\n",
      "           'age': 1,\n",
      "           'at': 1,\n",
      "           'began': 1,\n",
      "           'building': 1,\n",
      "           'of': 1,\n",
      "           'the': 1},\n",
      " 'sent1': {'Construction': 1,\n",
      "           'and': 1,\n",
      "           'by': 1,\n",
      "           'carpenters.': 1,\n",
      "           'done': 1,\n",
      "           'local': 1,\n",
      "           'masons': 1,\n",
      "           'mostly': 1,\n",
      "           'was': 1},\n",
      " 'sent2': {'1770.': 1,\n",
      "           'He': 1,\n",
      "           'Pavilion': 1,\n",
      "           'South': 1,\n",
      "           'in': 1,\n",
      "           'into': 1,\n",
      "           'moved': 1,\n",
      "           'the': 1},\n",
      " 'sent3': {\"Jefferson's\": 1,\n",
      "           'Monticello': 1,\n",
      "           'Turning': 1,\n",
      "           'a': 1,\n",
      "           'into': 1,\n",
      "           'masterpiece': 1,\n",
      "           'neoclassical': 1,\n",
      "           'obsession.': 1,\n",
      "           'was': 1}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "corpus = {}\n",
    "\n",
    "\"\"\"\n",
    "Normally you should use .splitlines() \n",
    "but here you explicitly add a single '\\n' character to the end of each line/\n",
    "sentence, so you need to explicitly split on this character.\n",
    "\"\"\"\n",
    "for i, sent in enumerate(sentences.split('\\n')):  # 对每一句话生成一个beg of word vector\n",
    "    corpus['sent{}'.format(i)] = dict((tok, 1) for tok in sent.split())\n",
    "    \n",
    "pp = pprint.PrettyPrinter()\n",
    "pp.pprint(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thomas</th>\n",
       "      <th>Jefferson</th>\n",
       "      <th>began</th>\n",
       "      <th>building</th>\n",
       "      <th>Monticello</th>\n",
       "      <th>at</th>\n",
       "      <th>the</th>\n",
       "      <th>age</th>\n",
       "      <th>of</th>\n",
       "      <th>26.</th>\n",
       "      <th>...</th>\n",
       "      <th>South</th>\n",
       "      <th>Pavilion</th>\n",
       "      <th>in</th>\n",
       "      <th>1770.</th>\n",
       "      <th>Turning</th>\n",
       "      <th>a</th>\n",
       "      <th>neoclassical</th>\n",
       "      <th>masterpiece</th>\n",
       "      <th>Jefferson's</th>\n",
       "      <th>obsession.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sent0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sent1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sent2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sent3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Thomas  Jefferson  began  building  Monticello  at  the  age  of  26.  \\\n",
       "sent0       1          1      1         1           1   1    1    1   1    1   \n",
       "sent1       0          0      0         0           0   0    0    0   0    0   \n",
       "sent2       0          0      0         0           0   0    1    0   0    0   \n",
       "sent3       0          0      0         0           1   0    0    0   0    0   \n",
       "\n",
       "       ...  South  Pavilion  in  1770.  Turning  a  neoclassical  masterpiece  \\\n",
       "sent0  ...      0         0   0      0        0  0             0            0   \n",
       "sent1  ...      0         0   0      0        0  0             0            0   \n",
       "sent2  ...      1         1   1      1        0  0             0            0   \n",
       "sent3  ...      0         0   0      0        1  1             1            1   \n",
       "\n",
       "       Jefferson's  obsession.  \n",
       "sent0            0           0  \n",
       "sent1            0           0  \n",
       "sent2            0           0  \n",
       "sent3            1           1  \n",
       "\n",
       "[4 rows x 32 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_records(corpus).fillna(0).astype(int).T\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity between sentence\n",
    "\n",
    "One way to check for the similarities between sentences is to count the number of overlapping tokens using a **dot product**. (also called the scalar product because it produces a single scalar value as its output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = pd.np.array([1, 2, 3])\n",
    "v2 = pd.np.array([2, 3, 4])\n",
    "v1.dot(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(v1 * v2).sum()  # fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([x1 * x2 for x1, x2 in zip(v1, v2)])  # slow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use numpy matrix product operatior, np.matmul() function or the @ operator\n",
    "v1.reshape(-1, 1).T @v2.reshape(-1, 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thomas</th>\n",
       "      <th>Jefferson</th>\n",
       "      <th>began</th>\n",
       "      <th>building</th>\n",
       "      <th>Monticello</th>\n",
       "      <th>at</th>\n",
       "      <th>the</th>\n",
       "      <th>age</th>\n",
       "      <th>of</th>\n",
       "      <th>26.</th>\n",
       "      <th>...</th>\n",
       "      <th>South</th>\n",
       "      <th>Pavilion</th>\n",
       "      <th>in</th>\n",
       "      <th>1770.</th>\n",
       "      <th>Turning</th>\n",
       "      <th>a</th>\n",
       "      <th>neoclassical</th>\n",
       "      <th>masterpiece</th>\n",
       "      <th>Jefferson's</th>\n",
       "      <th>obsession.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sent0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sent1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sent2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sent3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Thomas  Jefferson  began  building  Monticello  at  the  age  of  26.  \\\n",
       "sent0       1          1      1         1           1   1    1    1   1    1   \n",
       "sent1       0          0      0         0           0   0    0    0   0    0   \n",
       "sent2       0          0      0         0           0   0    1    0   0    0   \n",
       "sent3       0          0      0         0           1   0    0    0   0    0   \n",
       "\n",
       "       ...  South  Pavilion  in  1770.  Turning  a  neoclassical  masterpiece  \\\n",
       "sent0  ...      0         0   0      0        0  0             0            0   \n",
       "sent1  ...      0         0   0      0        0  0             0            0   \n",
       "sent2  ...      1         1   1      1        0  0             0            0   \n",
       "sent3  ...      0         0   0      0        1  1             1            1   \n",
       "\n",
       "       Jefferson's  obsession.  \n",
       "sent0            0           0  \n",
       "sent1            0           0  \n",
       "sent2            0           0  \n",
       "sent3            1           1  \n",
       "\n",
       "[4 rows x 32 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent0</th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>sent3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Thomas</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Jefferson</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>began</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>building</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Monticello</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>at</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>the</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>age</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>of</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Construction</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>was</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>done</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mostly</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>by</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>local</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>masons</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>and</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>carpenters.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>He</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>moved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>into</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>South</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Pavilion</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>in</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1770.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Turning</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>neoclassical</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>masterpiece</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Jefferson's</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>obsession.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sent0  sent1  sent2  sent3\n",
       "Thomas            1      0      0      0\n",
       "Jefferson         1      0      0      0\n",
       "began             1      0      0      0\n",
       "building          1      0      0      0\n",
       "Monticello        1      0      0      1\n",
       "at                1      0      0      0\n",
       "the               1      0      1      0\n",
       "age               1      0      0      0\n",
       "of                1      0      0      0\n",
       "26.               1      0      0      0\n",
       "Construction      0      1      0      0\n",
       "was               0      1      0      1\n",
       "done              0      1      0      0\n",
       "mostly            0      1      0      0\n",
       "by                0      1      0      0\n",
       "local             0      1      0      0\n",
       "masons            0      1      0      0\n",
       "and               0      1      0      0\n",
       "carpenters.       0      1      0      0\n",
       "He                0      0      1      0\n",
       "moved             0      0      1      0\n",
       "into              0      0      1      1\n",
       "South             0      0      1      0\n",
       "Pavilion          0      0      1      0\n",
       "in                0      0      1      0\n",
       "1770.             0      0      1      0\n",
       "Turning           0      0      0      1\n",
       "a                 0      0      0      1\n",
       "neoclassical      0      0      0      1\n",
       "masterpiece       0      0      0      1\n",
       "Jefferson's       0      0      0      1\n",
       "obsession.        0      0      0      1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.T\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sent0.dot(df.sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sent0.dot(df.sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sent0.dot(df.sent3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sent1.dot(df.sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sent1.dot(df.sent3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sent3.dot(df.sent2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面，我们可以查看同时出现的词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('into', 1)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k, v) for (k, v) in (df.sent2 & df.sent3).items() if v]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A token improvement\n",
    "\n",
    "很多时候，我们不仅仅需要根据空格切分，需要根据其他的特殊字符切分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thomas', 'Jefferson', 'began', 'building', 'Monticello', 'at', 'the', 'age', 'of', '26', '']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "tokens = re.split(r'[-\\s.,;!?]+', sentence)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regex\n",
    "\n",
    "注意，当我们需要通过-字符切分时，-字符必须放在open bracket 右侧，即第一个。原因是-在一个character class 中有特殊的意义，例如:r'[A-Z]' 表明匹配任意一个大写字符。\n",
    "\n",
    "`re.split` 和`str.split`的行为类似，只是根据regex 的正则表达式的匹配作为分隔符。\n",
    "\n",
    "- `[...]` 定义一个character class，匹配任意一个即可\n",
    "- `(...)` 定义一个regex group，需要全部匹配\n",
    "\n",
    "#### compiled regex 的好处：\n",
    "- 更快：Python caches the compiled objects for the last MAXCACHE=100 regular expressions.\n",
    "\n",
    "然后，我们尝试移除无效的token，例如空字符等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thomas',\n",
       " 'Jefferson',\n",
       " 'began',\n",
       " 'building',\n",
       " 'Monticello',\n",
       " 'at',\n",
       " 'the',\n",
       " 'age',\n",
       " 'of',\n",
       " '26']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile(r\"([-\\s.,;!?])+\")\n",
    "tokens = pattern.split(sentence)\n",
    "[x for x in tokens if x and x not in '- \\t\\n.,;!?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thomas',\n",
       " 'Jefferson',\n",
       " 'began',\n",
       " 'building',\n",
       " 'Monticello',\n",
       " 'at',\n",
       " 'the',\n",
       " 'age',\n",
       " 'of',\n",
       " '26']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第二种方法，使用filter\n",
    "list(filter(lambda x: x if x and x not in '- \\t\\n.,;!?' else None, tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenizer libraries:\n",
    "\n",
    "- spaCy — Accurate , flexible, fast, Python\n",
    "- Stanford CoreNLP — More accurate, less flexible, fast, depends on Java 8\n",
    "- NLTK — Standard used by many NLP contests and comparisons, popular, Python\n",
    "\n",
    "我们下面首先来看一个NLTK tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thomas',\n",
       " 'Jefferson',\n",
       " 'began',\n",
       " 'building',\n",
       " 'Monticello',\n",
       " 'at',\n",
       " 'the',\n",
       " 'age',\n",
       " 'of',\n",
       " '26',\n",
       " '.']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+|$[0-9.]+|\\S+')\n",
    "tokenizer.tokenize(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also separates sentence-ending trailing punctuation from tokens that do not contain any other punctuation characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TreeBank Tokenizer\n",
    "\n",
    "- separates phrase-terminating punctuation\n",
    "- English contractions: isn't = is n't\n",
    "    - 用途：syntax tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monticello',\n",
       " 'was',\n",
       " \"n't\",\n",
       " 'designated',\n",
       " 'as',\n",
       " 'UNESCO',\n",
       " 'World',\n",
       " 'Heritage',\n",
       " 'Site',\n",
       " 'until',\n",
       " '1987',\n",
       " '.']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "new_sentence = \"Monticello wasn't designated as UNESCO World Heritage Site until 1987.\"\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "tokenizer.tokenize(new_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Casual Tokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT',\n",
       " '@TJMonticello',\n",
       " 'Best',\n",
       " 'day',\n",
       " 'everrrrrrr',\n",
       " 'at',\n",
       " 'Monticello',\n",
       " '.',\n",
       " 'Awesommmmmmeeeeeeee',\n",
       " 'day',\n",
       " ':*)']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize.casual import casual_tokenize\n",
    "message = \"RT @TJMonticello Best day everrrrrrr at Monticello. Awesommmmmmeeeeeeee day :*)\"\"\"\n",
    "casual_tokenize(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT',\n",
       " 'Best',\n",
       " 'day',\n",
       " 'everrr',\n",
       " 'at',\n",
       " 'Monticello',\n",
       " '.',\n",
       " 'Awesommmeee',\n",
       " 'day',\n",
       " ':*)']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduce_len: reduce the number of repeated characters within a token\n",
    "# strip_handles: strip usernames\n",
    "casual_tokenize(message, reduce_len=True, strip_handles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
