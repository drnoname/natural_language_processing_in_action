{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq\n",
    "\n",
    "本文介绍以下知识点：\n",
    "- Mapping one text sequence to another with a neural network\n",
    "- Understanding sequence-to-sequence tasks and how they’re different from the others you’ve learned about\n",
    "- Using encoder-decoder model architectures for translation and chat\n",
    "- Training a model to pay attention to what is important in a sequence\n",
    "\n",
    "seq2seq model 的输入和输出可以是不同的length.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Encoder-Decoder Architecture\n",
    "\n",
    "- **sequence encoder**:\n",
    "    - input: a sequence (e.g., text)\n",
    "    - output: lower dimension representation (e.g., thought vector)\n",
    "\n",
    "这个我们在前面的LSTM 网络结构中已经见过了。\n",
    "\n",
    "- **sequence decoder**:\n",
    "    - input: vector\n",
    "    - output: a sequence (e.g., text)\n",
    "    \n",
    "这个有些类似我们之前用LSTM 网络生成文字的，但是也有不同，因为我们不能让它随机输出，而是要输出特定的内容。\n",
    "\n",
    "encoder 部分，LSTM 把语义encode 成一个thought vector (也称作**context vector**). 这个thought vector 就是我们的**information bottleneck**。 相当于把一句话的意思压缩成一个n-dimensional vector. \n",
    "\n",
    "然后这个thought vector 作为decoder network 的input. 如下图所示。\n",
    "\n",
    "<img src=\"img/thought_vector.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "这个thought vector 包含两部分：\n",
    "- memory state `state_c`\n",
    "- output of hidden layer `state_h`\n",
    "\n",
    "然后我们设置`return_state=True`，LSTM model 会输出hidden layer state.\n",
    "\n",
    "decoder network 使用thought vector 作为输入的初始状态，然后需要一个**start token**, 然后就可以generate 后续的tokens 了。\n",
    "如下图所示。\n",
    "\n",
    "<img src=\"img/next_word_prediction.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "#### training stage\n",
    "\n",
    "- starting text: input to encoder\n",
    "- expected text: input to decoder\n",
    "\n",
    "#### inference stage\n",
    "\n",
    "encoder 部分就是一个LSTM network，下面我们focus 在decoder 部分。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 对比other techniques\n",
    "\n",
    "#### Auto-Encoder\n",
    "\n",
    "这和auto-encoder 很像，auto-encoder 也是在某个中间层找到一个低维的**bottle of information**，使用了encoder-decoder architecture.\n",
    "\n",
    "区别在于，auto-encoder 的目标时寻找一个dense vector representation（相当于数据压缩），目标是能够尽可能地还原原数据。也就是输入和输出时相同的。而seq2seq 的输入和输出是不同的seq，但是具有相同的meaning.\n",
    "\n",
    "- **variational auto-encoder**: dense vector 服从高斯分布\n",
    "\n",
    "#### PCA\n",
    "PCA 的目标是降维，通常降至2维或3维。而且不是面向变长的time-series data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 translation v.s. chatbot\n",
    "\n",
    "translation 和chatbot 都需要把一个sequence map 到另一个sequence。但是区别在于，chatbot 需要学习更加复杂的mapping。\n",
    "- 需要更多的数据: enough Q&A pairs\n",
    "- 更高维度的thought vector ———— 需要encode all the information about the world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Challenges\n",
    "\n",
    "#### 挑战1: 输入和输出的长度不同\n",
    "\n",
    "例如，我们需要把英文翻译成德语，可能输入的长度和输出的长度不同。\n",
    "\n",
    "<img src=\"img/translation.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "#### 挑战2: More control on generative model\n",
    "\n",
    "之前的LSTM 生成token 的过程如下图所示：\n",
    "\n",
    "<img src=\"img/unrolled_encoder_decoder.png\" alt=\"drawing\" width=\"700\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Assembling a sequence-to-sequence pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
